{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame with the specified columns\n",
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "\n",
    "# Show the empty DataFrame\n",
    "data = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>replicates</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>distortion</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745803</td>\n",
       "      <td>0.854396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.867924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>_19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987047</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.872852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>_19</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>_19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.967848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>_19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.874607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>-12</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>_19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      round  split replicates  duplicates  distortion        m1        m2  \\\n",
       "0        -1    0.0          0         8.0           1  1.000000  0.745803   \n",
       "1        -1    0.0          0       100.0           1  0.997500  0.802817   \n",
       "2        -1    0.0          0         0.1           0  0.967742  0.952381   \n",
       "3        -1    0.0          0         1.0           0  1.000000  0.919192   \n",
       "4        -1    0.0          0         0.1           1  1.000000  0.766667   \n",
       "...     ...    ...        ...         ...         ...       ...       ...   \n",
       "1907    -12   -2.0        _19         1.0           1  0.987047  0.782341   \n",
       "1908    -12   -2.0        _19         0.1           1  1.000000  0.783333   \n",
       "1909    -12   -2.0        _19         8.0           0  1.000000  0.937700   \n",
       "1910    -12   -2.0        _19         8.0           1  0.998973  0.777778   \n",
       "1911    -12   -2.0        _19         1.0           0  1.000000  0.919192   \n",
       "\n",
       "            m3  \n",
       "0     0.854396  \n",
       "1     0.889632  \n",
       "2     0.960000  \n",
       "3     0.957895  \n",
       "4     0.867924  \n",
       "...        ...  \n",
       "1907  0.872852  \n",
       "1908  0.878505  \n",
       "1909  0.967848  \n",
       "1910  0.874607  \n",
       "1911  0.957895  \n",
       "\n",
       "[1912 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN values with 0\n",
    "data_filled = data.fillna(0)\n",
    "\n",
    "# Ensure all columns except 'replicates' (since it might contain non-numeric values originally) are numeric\n",
    "data_filled = data_filled.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Display the data types to confirm changes\n",
    "data_filled.dtypes, data_filled.head()\n",
    "\n",
    "data_filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>replicates</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>distortion</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745803</td>\n",
       "      <td>0.854396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.867924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987047</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.872852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.967848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.874607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      round  split  replicates  duplicates  distortion  precision    recall  \\\n",
       "0         1    0.0           0         8.0           1   1.000000  0.745803   \n",
       "1         1    0.0           0       100.0           1   0.997500  0.802817   \n",
       "2         1    0.0           0         0.1           0   0.967742  0.952381   \n",
       "3         1    0.0           0         1.0           0   1.000000  0.919192   \n",
       "4         1    0.0           0         0.1           1   1.000000  0.766667   \n",
       "...     ...    ...         ...         ...         ...        ...       ...   \n",
       "1907     12    2.0          19         1.0           1   0.987047  0.782341   \n",
       "1908     12    2.0          19         0.1           1   1.000000  0.783333   \n",
       "1909     12    2.0          19         8.0           0   1.000000  0.937700   \n",
       "1910     12    2.0          19         8.0           1   0.998973  0.777778   \n",
       "1911     12    2.0          19         1.0           0   1.000000  0.919192   \n",
       "\n",
       "       f1score  \n",
       "0     0.854396  \n",
       "1     0.889632  \n",
       "2     0.960000  \n",
       "3     0.957895  \n",
       "4     0.867924  \n",
       "...        ...  \n",
       "1907  0.872852  \n",
       "1908  0.878505  \n",
       "1909  0.967848  \n",
       "1910  0.874607  \n",
       "1911  0.957895  \n",
       "\n",
       "[1912 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove \"_\" from the 'replicates' column and convert to numeric if possible\n",
    "data_filled['replicates'] = data_filled['replicates'].astype(str).str.replace(\"_\", \"\")\n",
    "data_filled['replicates'] = pd.to_numeric(data_filled['replicates'], errors='coerce').fillna(0)\n",
    "\n",
    "# Make 'round' and 'split' values positive\n",
    "data_filled['round'] = data_filled['round'].abs()\n",
    "data_filled['split'] = data_filled['split'].abs()\n",
    "\n",
    "\n",
    "# Rename columns 'm1', 'm2', 'm3' to 'precision', 'recall', 'f1score'\n",
    "data_renamed = data_filled.rename(columns={'m1': 'precision', 'm2': 'recall', 'm3': 'f1score'})\n",
    "\n",
    "# Display the first few rows to confirm the column names have been updated\n",
    "data_renamed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prior</th>\n",
       "      <th>duplicates_level</th>\n",
       "      <th>distortion_level</th>\n",
       "      <th>replicates</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both</td>\n",
       "      <td>Pitman</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745803</td>\n",
       "      <td>0.854396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both</td>\n",
       "      <td>Pitman</td>\n",
       "      <td>Very High</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Both</td>\n",
       "      <td>Pitman</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both</td>\n",
       "      <td>Pitman</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both</td>\n",
       "      <td>Pitman</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.867924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>No Empirical</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>19</td>\n",
       "      <td>0.987047</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.872852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>No Empirical</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>No Empirical</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.967848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>No Empirical</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>19</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.874607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>No Empirical</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             model        prior duplicates_level distortion_level  replicates  \\\n",
       "0             Both       Pitman             High             High           0   \n",
       "1             Both       Pitman        Very High             High           0   \n",
       "2             Both       Pitman              Low              Low           0   \n",
       "3             Both       Pitman           Medium              Low           0   \n",
       "4             Both       Pitman              Low             High           0   \n",
       "...            ...          ...              ...              ...         ...   \n",
       "1907  No Empirical  Bounded NBD           Medium             High          19   \n",
       "1908  No Empirical  Bounded NBD              Low             High          19   \n",
       "1909  No Empirical  Bounded NBD             High              Low          19   \n",
       "1910  No Empirical  Bounded NBD             High             High          19   \n",
       "1911  No Empirical  Bounded NBD           Medium              Low          19   \n",
       "\n",
       "      precision    recall   f1score  \n",
       "0      1.000000  0.745803  0.854396  \n",
       "1      0.997500  0.802817  0.889632  \n",
       "2      0.967742  0.952381  0.960000  \n",
       "3      1.000000  0.919192  0.957895  \n",
       "4      1.000000  0.766667  0.867924  \n",
       "...         ...       ...       ...  \n",
       "1907   0.987047  0.782341  0.872852  \n",
       "1908   1.000000  0.783333  0.878505  \n",
       "1909   1.000000  0.937700  0.967848  \n",
       "1910   0.998973  0.777778  0.874607  \n",
       "1911   1.000000  0.919192  0.957895  \n",
       "\n",
       "[1912 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to map 'round' values to model names\n",
    "def map_round_to_model(round_number):\n",
    "    if 1 <= round_number <= 3:\n",
    "        return \"Both\"\n",
    "    elif 4 <= round_number <= 6:\n",
    "        return \"No Diri\"\n",
    "    elif 7 <= round_number <= 9:\n",
    "        return \"None\"\n",
    "    elif 10 <= round_number <= 12:\n",
    "        return \"No Empirical\"\n",
    "    else:\n",
    "        return \"Unknown\"  # For any round numbers outside the specified ranges\n",
    "\n",
    "# Apply the mapping function to the 'round' column to create the new 'model' column\n",
    "data_renamed['model'] = data_renamed['round'].apply(map_round_to_model)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to map 'round' values to prior categories\n",
    "def map_round_to_prior(round_number):\n",
    "    if round_number in [1, 4, 7, 10]:\n",
    "        return \"Pitman\"\n",
    "    elif round_number in [2, 5, 8, 11]:\n",
    "        return \"uniform\"\n",
    "    elif round_number in [3, 6, 9, 12]:\n",
    "        return \"Bounded NBD\"\n",
    "    else:\n",
    "        return \"Unknown\"  # For any round numbers outside the specified or considered ranges\n",
    "\n",
    "# Apply the mapping function to the 'round' column to create the new 'prior' column\n",
    "data_renamed['prior'] = data_renamed['round'].apply(map_round_to_prior)\n",
    "\n",
    "# Define a function to map 'duplicates' values to duplicates level categories\n",
    "def map_duplicates_to_level(duplicates_value):\n",
    "    if duplicates_value == 0.1:\n",
    "        return \"Low\"\n",
    "    elif duplicates_value == 1.0:\n",
    "        return \"Medium\"\n",
    "    elif duplicates_value == 8.0:\n",
    "        return \"High\"\n",
    "    elif duplicates_value == 100.0:\n",
    "        return \"Very High\"\n",
    "    else:\n",
    "        return \"Unknown\"  # For any duplicates values outside the specified ranges\n",
    "\n",
    "# Apply the mapping function to the 'duplicates' column to create the new 'duplicates_level' column\n",
    "data_renamed['duplicates_level'] = data_renamed['duplicates'].apply(map_duplicates_to_level)\n",
    "\n",
    "# Define a function to map 'distortion' values to distortion level categories\n",
    "def map_distortion_to_level(distortion_value):\n",
    "    if distortion_value == 0:\n",
    "        return \"Low\"\n",
    "    elif distortion_value == 1:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Unknown\"  # For any distortion values outside the specified values\n",
    "\n",
    "# Apply the mapping function to the 'distortion' column to create the new 'distortion_level' column\n",
    "data_renamed['distortion_level'] = data_renamed['distortion'].apply(map_distortion_to_level)\n",
    "\n",
    "# Select only the specified columns\n",
    "data_selected_columns = data_renamed[['model', 'prior', 'duplicates_level', 'distortion_level', 'replicates']]\n",
    "\n",
    "# Select and reorder the dataset with only the specified columns\n",
    "data_final = data_renamed[['model', 'prior', 'duplicates_level', 'distortion_level', \n",
    "                           'replicates', 'precision', 'recall', 'f1score']]\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "data_final\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prior</th>\n",
       "      <th>duplicates_level</th>\n",
       "      <th>distortion_level</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>0.857191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.935863</td>\n",
       "      <td>0.966809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Both</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750833</td>\n",
       "      <td>0.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.984426</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.968135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both</td>\n",
       "      <td>Bounded NBD</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>0.985199</td>\n",
       "      <td>0.760986</td>\n",
       "      <td>0.858368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>None</td>\n",
       "      <td>uniform</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.305915</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.463033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>None</td>\n",
       "      <td>uniform</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>0.978620</td>\n",
       "      <td>0.839425</td>\n",
       "      <td>0.903667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>None</td>\n",
       "      <td>uniform</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>0.921515</td>\n",
       "      <td>0.958799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>uniform</td>\n",
       "      <td>Very High</td>\n",
       "      <td>High</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.827264</td>\n",
       "      <td>0.905395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>None</td>\n",
       "      <td>uniform</td>\n",
       "      <td>Very High</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922124</td>\n",
       "      <td>0.959484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        prior duplicates_level distortion_level  precision_mean  \\\n",
       "0   Both  Bounded NBD             High             High        0.998371   \n",
       "1   Both  Bounded NBD             High              Low        0.999872   \n",
       "2   Both  Bounded NBD              Low             High        1.000000   \n",
       "3   Both  Bounded NBD              Low              Low        0.984426   \n",
       "4   Both  Bounded NBD           Medium             High        0.985199   \n",
       "..   ...          ...              ...              ...             ...   \n",
       "91  None      uniform              Low              Low        0.305915   \n",
       "92  None      uniform           Medium             High        0.978620   \n",
       "93  None      uniform           Medium              Low        0.999236   \n",
       "94  None      uniform        Very High             High        0.999837   \n",
       "95  None      uniform        Very High              Low        1.000000   \n",
       "\n",
       "    recall_mean  f1score_mean  \n",
       "0      0.751479      0.857191  \n",
       "1      0.935863      0.966809  \n",
       "2      0.750833      0.857600  \n",
       "3      0.952381      0.968135  \n",
       "4      0.760986      0.858368  \n",
       "..          ...           ...  \n",
       "91     0.952381      0.463033  \n",
       "92     0.839425      0.903667  \n",
       "93     0.921515      0.958799  \n",
       "94     0.827264      0.905395  \n",
       "95     0.922124      0.959484  \n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the specified columns and compute mean and standard deviation for precision, recall, and f1score\n",
    "grouped_data = data_final.groupby(['model', 'prior', 'duplicates_level', 'distortion_level'])\n",
    "\n",
    "# Compute mean\n",
    "mean_values = grouped_data[['precision', 'recall', 'f1score']].mean().reset_index()\n",
    "\n",
    "# Compute standard deviation\n",
    "std_dev_values = grouped_data[['precision', 'recall', 'f1score']].std().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "mean_values.rename(columns={\n",
    "    'precision': 'precision_mean', \n",
    "    'recall': 'recall_mean', \n",
    "    'f1score': 'f1score_mean'}, inplace=True)\n",
    "\n",
    "std_dev_values.rename(columns={\n",
    "    'precision': 'precision_std', \n",
    "    'recall': 'recall_std', \n",
    "    'f1score': 'f1score_std'}, inplace=True)\n",
    "\n",
    "# Display the mean values\n",
    "mean_values.head(), std_dev_values.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge mean and standard deviation dataframes on the groupby columns\n",
    "combined_data = pd.merge(mean_values, std_dev_values, \n",
    "                         on=['model', 'prior', 'duplicates_level', 'distortion_level'])\n",
    "\n",
    "# Display the combined dataframe\n",
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv(\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use both and PitmanYou prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "both_Pit_pre_mean = []\n",
    "both_Pit_pre_sd = []\n",
    "both_Pit_recall_mean = []\n",
    "both_Pit_recall_sd = []\n",
    "both_Pit_f1score_mean = []\n",
    "both_Pit_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -1) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        both_Pit_pre_mean.append(np.mean(precision_values))\n",
    "        both_Pit_recall_mean.append(np.mean(recall_values))\n",
    "        both_Pit_f1score_mean.append(np.mean(f1score_values))\n",
    "        both_Pit_pre_sd.append(np.std(precision_values))\n",
    "        both_Pit_recall_sd.append(np.std(recall_values))\n",
    "        both_Pit_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use both and Uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_Unif_pre_mean = []\n",
    "both_Unif_pre_sd = []\n",
    "both_Unif_recall_mean = []\n",
    "both_Unif_recall_sd = []\n",
    "both_Unif_f1score_mean = []\n",
    "both_Unif_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -2) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        both_Unif_pre_mean.append(np.mean(precision_values))\n",
    "        both_Unif_recall_mean.append(np.mean(recall_values))\n",
    "        both_Unif_f1score_mean.append(np.mean(f1score_values))\n",
    "        both_Unif_pre_sd.append(np.std(precision_values))\n",
    "        both_Unif_recall_sd.append(np.std(recall_values))\n",
    "        both_Unif_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41759702,\n",
       " 0.99978118,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.49330822999999996,\n",
       " 0.9795172300000001,\n",
       " 0.9990920500000001,\n",
       " 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_Unif_pre_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use both and Bounded NBD prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_BNBD_pre_mean = []\n",
    "both_BNBD_pre_sd = []\n",
    "both_BNBD_recall_mean = []\n",
    "both_BNBD_recall_sd = []\n",
    "both_BNBD_f1score_mean = []\n",
    "both_BNBD_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -3) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        both_BNBD_pre_mean.append(np.mean(precision_values))\n",
    "        both_BNBD_recall_mean.append(np.mean(recall_values))\n",
    "        both_BNBD_f1score_mean.append(np.mean(f1score_values))\n",
    "        both_BNBD_pre_sd.append(np.std(precision_values))\n",
    "        both_BNBD_recall_sd.append(np.std(recall_values))\n",
    "        both_BNBD_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_pair_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the DataFrame with each column corresponding to the first element of each tuple from the pairs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn1\u001b[39m\u001b[38;5;124m'\u001b[39m: [tup[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43marray_pair_1\u001b[49m[\u001b[38;5;241m0\u001b[39m], array_pair_1[\u001b[38;5;241m1\u001b[39m])],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn2\u001b[39m\u001b[38;5;124m'\u001b[39m: [tup[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_pair_2[\u001b[38;5;241m0\u001b[39m], array_pair_2[\u001b[38;5;241m1\u001b[39m])],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn3\u001b[39m\u001b[38;5;124m'\u001b[39m: [tup[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_pair_3[\u001b[38;5;241m0\u001b[39m], array_pair_3[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m      6\u001b[0m })\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_table)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array_pair_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame with each column corresponding to the first element of each tuple from the pairs\n",
    "df_table = pd.DataFrame({\n",
    "    'Column1': [tup[0] for tup in zip(array_pair_1[0], array_pair_1[1])],\n",
    "    'Column2': [tup[0] for tup in zip(array_pair_2[0], array_pair_2[1])],\n",
    "    'Column3': [tup[0] for tup in zip(array_pair_3[0], array_pair_3[1])]\n",
    "})\n",
    "\n",
    "print(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the DataFrame with each column corresponding to the first element of each tuple from the pairs\n",
    "df_table = pd.DataFrame({\n",
    "    'Column1': [tup[0] for tup in zip(array_pair_1[0], array_pair_1[1])],\n",
    "    'Column2': [tup[0] for tup in zip(array_pair_2[0], array_pair_2[1])],\n",
    "    'Column3': [tup[0] for tup in zip(array_pair_3[0], array_pair_3[1])]\n",
    "})\n",
    "\n",
    "print(df_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Diri and PitmanYou prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_diri_Pit_pre_mean = []\n",
    "no_diri_Pit_pre_sd = []\n",
    "no_diri_Pit_recall_mean = []\n",
    "no_diri_Pit_recall_sd = []\n",
    "no_diri_Pit_f1score_mean = []\n",
    "no_diri_Pit_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -4) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_diri_Pit_pre_mean.append(np.mean(precision_values))\n",
    "        no_diri_Pit_recall_mean.append(np.mean(recall_values))\n",
    "        no_diri_Pit_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_diri_Pit_pre_sd.append(np.std(precision_values))\n",
    "        no_diri_Pit_recall_sd.append(np.std(recall_values))\n",
    "        no_diri_Pit_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Diri and Uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_diri_Unif_pre_mean = []\n",
    "no_diri_Unif_pre_sd = []\n",
    "no_diri_Unif_recall_mean = []\n",
    "no_diri_Unif_recall_sd = []\n",
    "no_diri_Unif_f1score_mean = []\n",
    "no_diri_Unif_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -5) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_diri_Unif_pre_mean.append(np.mean(precision_values))\n",
    "        no_diri_Unif_recall_mean.append(np.mean(recall_values))\n",
    "        no_diri_Unif_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_diri_Unif_pre_sd.append(np.std(precision_values))\n",
    "        no_diri_Unif_recall_sd.append(np.std(recall_values))\n",
    "        no_diri_Unif_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Diri and Bounded NBD prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_diri_BNBD_pre_mean = []\n",
    "no_diri_BNBD_pre_sd = []\n",
    "no_diri_BNBD_recall_mean = []\n",
    "no_diri_BNBD_recall_sd = []\n",
    "no_diri_BNBD_f1score_mean = []\n",
    "no_diri_BNBD_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -6) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_diri_BNBD_pre_mean.append(np.mean(precision_values))\n",
    "        no_diri_BNBD_recall_mean.append(np.mean(recall_values))\n",
    "        no_diri_BNBD_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_diri_BNBD_pre_sd.append(np.std(precision_values))\n",
    "        no_diri_BNBD_recall_sd.append(np.std(recall_values))\n",
    "        no_diri_BNBD_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# both NO and PitmanYou prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_Pit_pre_mean = []\n",
    "no_Pit_pre_sd = []\n",
    "no_Pit_recall_mean = []\n",
    "no_Pit_recall_sd = []\n",
    "no_Pit_f1score_mean = []\n",
    "no_Pit_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -7) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_Pit_pre_mean.append(np.mean(precision_values))\n",
    "        no_Pit_recall_mean.append(np.mean(recall_values))\n",
    "        no_Pit_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_Pit_pre_sd.append(np.std(precision_values))\n",
    "        no_Pit_recall_sd.append(np.std(recall_values))\n",
    "        no_Pit_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# both NO and Uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_Unif_pre_mean = []\n",
    "no_Unif_pre_sd = []\n",
    "no_Unif_recall_mean = []\n",
    "no_Unif_recall_sd = []\n",
    "no_Unif_f1score_mean = []\n",
    "no_Unif_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -8) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_Unif_pre_mean.append(np.mean(precision_values))\n",
    "        no_Unif_recall_mean.append(np.mean(recall_values))\n",
    "        no_Unif_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_Unif_pre_sd.append(np.std(precision_values))\n",
    "        no_Unif_recall_sd.append(np.std(recall_values))\n",
    "        no_Unif_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# both NO and Bounded NBD prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_BNBD_pre_mean = []\n",
    "no_BNBD_pre_sd = []\n",
    "no_BNBD_recall_mean = []\n",
    "no_BNBD_recall_sd = []\n",
    "no_BNBD_f1score_mean = []\n",
    "no_BNBD_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -9) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_BNBD_pre_mean.append(np.mean(precision_values))\n",
    "        no_BNBD_recall_mean.append(np.mean(recall_values))\n",
    "        no_BNBD_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_BNBD_pre_sd.append(np.std(precision_values))\n",
    "        no_BNBD_recall_sd.append(np.std(recall_values))\n",
    "        no_BNBD_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Empirical and PitmanYou prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_emp_Pit_pre_mean = []\n",
    "no_emp_Pit_pre_sd = []\n",
    "no_emp_Pit_recall_mean = []\n",
    "no_emp_Pit_recall_sd = []\n",
    "no_emp_Pit_f1score_mean = []\n",
    "no_emp_Pit_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -10) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_emp_Pit_pre_mean.append(np.mean(precision_values))\n",
    "        no_emp_Pit_recall_mean.append(np.mean(recall_values))\n",
    "        no_emp_Pit_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_emp_Pit_pre_sd.append(np.std(precision_values))\n",
    "        no_emp_Pit_recall_sd.append(np.std(recall_values))\n",
    "        no_emp_Pit_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Empirical and Uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_emp_Unif_pre_mean = []\n",
    "no_emp_Unif_pre_sd = []\n",
    "no_emp_Unif_recall_mean = []\n",
    "no_emp_Unif_recall_sd = []\n",
    "no_emp_Unif_f1score_mean = []\n",
    "no_emp_Unif_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -11) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_emp_Unif_pre_mean.append(np.mean(precision_values))\n",
    "        no_emp_Unif_recall_mean.append(np.mean(recall_values))\n",
    "        no_emp_Unif_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_emp_Unif_pre_sd.append(np.std(precision_values))\n",
    "        no_emp_Unif_recall_sd.append(np.std(recall_values))\n",
    "        no_emp_Unif_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Empirical and Bounded NBD prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = [0.1, 1, 8, 100]\n",
    "dist = [0,1]\n",
    "# the order is \n",
    "# L.L., M.L., H.L., VH.L., L.H., M.H., V.H., V.H. H.\n",
    "no_emp_BNBD_pre_mean = []\n",
    "no_emp_BNBD_pre_sd = []\n",
    "no_emp_BNBD_recall_mean = []\n",
    "no_emp_BNBD_recall_sd = []\n",
    "no_emp_BNBD_f1score_mean = []\n",
    "no_emp_BNBD_f1score_sd = []\n",
    "for i in dist:\n",
    "    for j in dup:\n",
    "        filtered_df = df[\n",
    "            (df['round'] == -12) &\n",
    "            (df['split'].isna() | (df['split'] == -2.0)) &\n",
    "            (df['duplicates'] == j) &\n",
    "            (df['distortion'] == i)\n",
    "        ]\n",
    "        precision_values = filtered_df['m1'].values\n",
    "        recall_values = filtered_df['m2'].values\n",
    "        f1score_values = filtered_df['m3'].values\n",
    "        no_emp_BNBD_pre_mean.append(np.mean(precision_values))\n",
    "        no_emp_BNBD_recall_mean.append(np.mean(recall_values))\n",
    "        no_emp_BNBD_f1score_mean.append(np.mean(f1score_values))\n",
    "        no_emp_BNBD_pre_sd.append(np.std(precision_values))\n",
    "        no_emp_BNBD_recall_sd.append(np.std(recall_values))\n",
    "        no_emp_BNBD_f1score_sd.append(np.std(f1score_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
